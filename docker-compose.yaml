services:
  streamlit-app:
    build:
      context: ./streamlit_app
      dockerfile: dockerfile
    image: streamlit-dashboard-image
    container_name: streamlit-dashboard-runtime
    volumes:
      - /home/tranm/cert:/certs:ro
    command:
      [
        "streamlit",
        "run",
        "dashboard.py",
        "--server.port=7200",
      ]
    network_mode: host

#   llama3:
#     image: langchain4j/ollama-llama3
#     networks:
#       - llama3-network
#     container_name: llama3
#     restart: always

# networks:
#   llama3-network:
#     name: llama3-network